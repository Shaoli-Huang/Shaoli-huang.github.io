
@article{zeping24crossdiff,
  abbr={ECCV},
  title={Realistic Human Motion Generation with Cross-Diffusion Models},
  author={Ren, Zeping and Huang†, Shaoli and Li†, Xiu},
  year={2024},
  dimensions={true},
  code={https://github.com/wonderNo/crossdiff},
  website={https://wonderno.github.io/CrossDiff-webpage/},
  preview={crossdiff.gif},
  arxiv={https://arxiv.org/abs/2312.10993},
  selected={true}
}

@article{zhengdi24sign,
  abbr={ECCV},
  title={SignAvatars: A Large-scale 3D Sign Language Holistic Motion Dataset and Benchmark},
  author={Yu, Zhengdi and Huang†, Shaoli and Cheng, Yongkang and Bridal, Togal},
  year={2024},
  dimensions={true},
  code={https://github.com/ZhengdiYu/SignAvatars},
  website={https://anonymoususer4ai.github.io},
  preview={signavatar.gif},
  arxiv={https://arxiv.org/pdf/2310.20436},
  selected={true}
}

@article{jikai24light,
  abbr={ECCV},
  title={Exploring the Feature Extraction and Relation Modeling For Light-Weight Transformer Tracking},
  author={Zheng*, Jikai and Liang*, Mingjiang and Huang, Shaoli and Ning†, Jifeng},
  year={2024},
  dimensions={true},
  preview={lighttracker.png},
}

@article{chen2024taming,
  abbr={SIGGRAPH},
  title={Taming Diffusion Probabilistic Models for Character Control},
  author={Chen*, Rui and Shi*, Mingyi and Huang, Shaoli and Tan, Ping and Komura, Taku and Chen†, Xuelin},
  year={2024},
  dimensions={true},
  code={https://github.com/AIGAnimation/CAMDM},
  video={https://youtu.be/B2pbgZtGZvo},
  website={https://aiganimation.github.io/CAMDM/},
  preview={camdm.gif},
  selected={true}
}

@article{han2024hutumotion,
  title={HuTuMotion: Human-Tuned Navigation of Latent Motion Diffusion Models with Minimal Feedback},
  author={Han, Gaoge and Huang†, Shaoli and Gong, Mingming and Tang†, Jinglei},
  abbr={AAAI},
  dimensions={true},
  code={},
  preview={hutu.gif},
  website={},
  selected={true},
  year={2024}
}

@inproceedings{zhangtapmo,
  title={TapMo: Shape-aware Motion Generation of Skeleton-free Characters},
  author={Zhang*, Jiaxu and Huang*, Shaoli and Tu†, Zhigang and Chen, Xin and Zhan, Xiaohang and Gang, YU and Shan, Ying},
  abbr={ICLR},
  dimensions={true},
  code={https://github.com/Kebii/TapMo},
  preview={tapmo.gif},
  website={https://semanticdh.github.io/TapMo/},
  selected={true},
  year={2024}
}


@article{liu2024programmable,
  abbr={CVPR},
  title={Programmable Motion Generation for Open-Set Motion Control Tasks},
  author={Liu, Hanchao and Zhan†, Xiaohang and Huang, Shaoli and Mu†, Tai-Jiang and Shan, Ying},
  dimensions={true},
  code={https://github.com/HanchaoLiu/ProgMoGen},
  preview={progmogen.gif},
  website={https://hanchaoliu.github.io/Prog-MoGen/},
  selected={true},
  year={2024}
}


@inproceedings{liu2023lote,
  abbr={ICCV},
  dimensions={true},
  title={LoTE-Animal: A long time-span dataset for endangered animal behavior understanding},
  author={Liu*, Dan and Hou*, Jin and Huang*, Shaoli and Liu, Jing and He, Yuxin and Zheng, Bochuan and Ning†, Jifeng and Zhang, Jingdong},
  preview={lote.png},
  year={2023}
}

@article{zhi2023livelyspeaker,
  title={Livelyspeaker: Towards semantic-aware co-speech gesture generation},
  abbr={ICCV},
  dimensions={true},
  code={https://github.com/zyhbili/LivelySpeaker},
  preview={livelyspeaker.gif},
  website={},
  selected={true},
  author={Zhi*, Yihao and Cun*, Xiaodong and Chen, Xuelin and Shen, Xi and Guo, Wen and Huang, Shaoli and Gao†, Shenghua},
  year={2023}
}

@inproceedings{yu2023acr,
  title={ACR: Attention collaboration-based regressor for arbitrary two-hand reconstruction},
  author={Yu, Zhengdi and Huang†, Shaoli and Fang, Chen and Breckon, Toby P and Wang, Jue},
  abbr={CVPR},
  dimensions={true},
  code={https://github.com/ZhengdiYu/Arbitrary-Hands-3D-Reconstruction},
  preview={acr.gif},
  website={https://semanticdh.github.io/ACR/},
  selected={true},
  year={2023}
}

@inproceedings{zhao2023learning,
  title={Learning anchor transformations for 3d garment animation},
  author={Zhao, Fang and Li, Zekun and Huang†, Shaoli and Weng, Junwu and Zhou, Tianfei and Xie, Guo-Sen and Wang, Jue and Shan, Ying},
  abbr={CVPR},
  dimensions={true},
  preview={anchor.gif},
  website={https://semanticdh.github.io/AnchorDEF/},
  selected={true},
  year={2023}
}

@inproceedings{lin2023handobject,
  title={Harmonious Feature Learning for Interactive Hand-Object Pose Estimation},
  author={Lin, Zhifeng and Ding*, Changxing and Yao, Huan and Kuang, Zengsheng and Huang,Shaoli},
  abbr={CVPR},
  dimensions={true},
  preview={handobject.png},
  pdf={https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Harmonious_Feature_Learning_for_Interactive_Hand-Object_Pose_Estimation_CVPR_2023_paper.pdf},
  code={https://github.com/lzfff12/HFL-Net},
  year={2023}
}

@inproceedings{tang2023master,
  abbr={CVPR},
  dimensions={true},
  preview={master.png},
  title={Master: Meta style transformer for controllable zero-shot and few-shot artistic style transfer},
  author={Tang, Hao and Liu, Songhua and Lin, Tianwei and Huang, Shaoli and Li, Fu and He, Dongliang and Wang, Xinchao},
  pdf={https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Master_Meta_Style_Transformer_for_Controllable_Zero-Shot_and_Few-Shot_Artistic_CVPR_2023_paper.pdf},
  year={2023}
}



@article{zhang2023skinned,
  title={Skinned motion retargeting with residual perception of motion semantics \& geometry},
  author={Zhang, Jiaxu and Weng, Junwu and Kang, Di and Zhao, Fang and Huang, Shaoli and Zhe, Xuefei and Bao, Linchao and Shan, Ying and Wang, Jue and Tu, Zhigang},
  abbr={CVPR},
  dimensions={true},
  code={},
  preview={r2et.gif},
  website={https://semanticdh.github.io/R2ET/},
  selected={true},
  year={2023}
}

@inproceedings{zhong2022towards,
  title={Towards hard-positive query mining for detr-based human-object interaction detection},
  author={Zhong, Xubin and Ding, Changxing and Li, Zijian and Huang, Shaoli},
  abbr={ECCV},
  dimensions={true},
  preview={hoieccv.png},
  year={2022},
}

@inproceedings{hu2021we,
  abbr={MM},
  dimensions={true},
  title={Do we really need frame-by-frame annotation datasets for object tracking?},
  author={Hu*, Lei and Huang*, Shaoli and Wang, Shilei and Liu, Wei and Ning†, Jifeng},
  preview={lote.png},
  year={2021}
}

